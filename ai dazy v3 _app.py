import streamlit as st
import zipfile
import os
from pathlib import Path
import openai
from hdbscan import HDBSCAN
import json
import hashlib
import re

# ----------------------------
# ğŸŒˆ ê¸°ë³¸ í˜ì´ì§€ ì„¤ì •
# ----------------------------
st.set_page_config(page_title="AI dazy document sorter", page_icon="ğŸ—‚ï¸", layout="wide")

# ----------------------------
# ğŸ” OpenAI API í‚¤ ì„¤ì • (legacy)
# ----------------------------
openai.api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

if not openai.api_key:
    st.sidebar.error("ğŸš¨ OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤. secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()
else:
    st.sidebar.success("âœ… OpenAI Key ë¡œë“œ ì™„ë£Œ")

# ----------------------------
# ğŸ¨ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§• (ê¸°ì¡´ ìœ ì§€)
# ----------------------------
st.markdown(
    """
    <style>
    body { background-color: #f8f9fc; font-family: 'Pretendard', sans-serif; }
    .stButton>button {
        border-radius: 10px;
        background-color: #4a6cf7;
        color: white;
        border: none;
        padding: 0.6em 1.2em;
        font-weight: 600;
        transition: 0.2s;
    }
    .stButton>button:hover { background-color: #3451c1; }
    .status-bar {
        background-color: #595656;
        border-radius: 6px;
        padding: 0.5em;
        margin-top: 20px;
        font-size: 0.9em;
    }
    .log-box {
        background-color: #595656;
        border-radius: 6px;
        padding: 0.8em;
        margin-top: 10px;
        height: 120px;
        overflow-y: auto;
        font-size: 0.85em;
        border: 1px solid #dee2e6;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ----------------------------
# ğŸ§­ ì‚¬ì´ë“œë°” (ê¸°ì¡´ ìœ ì§€)
# ----------------------------
st.sidebar.title("âš™ï¸ ì„¤ì •")

lang = st.sidebar.selectbox("ğŸŒ ì–¸ì–´ ì„ íƒ", ["í•œêµ­ì–´", "English"])

# ----------------------------
# ğŸ“ ë©”ì¸ UI (ê¸°ì¡´ ìœ ì§€)
# ----------------------------
left_col, right_col = st.columns([1, 1])

with left_col:
    st.subheader("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader(
        "ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.md, .pdf, .txt)",
        accept_multiple_files=True,
        type=["md", "pdf", "txt"],
    )

if uploaded_files:
    uploaded_files = [f for f in uploaded_files if f and f.name.strip()]
    if not uploaded_files:
        st.error("â— ìœ íš¨í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

with right_col:
    st.subheader("ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ")
    zip_placeholder = st.empty()

# ----------------------------
# âš™ï¸ ìƒíƒœ / ë¡œê·¸ (ê¸°ì¡´ ìœ ì§€)
# ----------------------------
progress_placeholder = st.empty()
progress_text = st.empty()
log_box = st.empty()
logs = []

def log(msg):
    logs.append(msg)
    log_box.markdown(
        "<div class='log-box'>" + "<br>".join(logs[-10:]) + "</div>",
        unsafe_allow_html=True,
    )

# ----------------------------
# ğŸ§  ìºì‹œ
# ----------------------------
CACHE_DIR = Path(".cache")
CACHE_DIR.mkdir(exist_ok=True)

def load_cache(p):
    try:
        return json.loads(p.read_text()) if p.exists() else {}
    except Exception:
        return {}

def save_cache(p, d):
    p.write_text(json.dumps(d, ensure_ascii=False, indent=2))

EMBED_CACHE = CACHE_DIR / "embeddings.json"
GROUP_CACHE = CACHE_DIR / "group_names.json"
README_CACHE = CACHE_DIR / "readmes.json"

embedding_cache = load_cache(EMBED_CACHE)
group_cache = load_cache(GROUP_CACHE)
readme_cache = load_cache(README_CACHE)

def h(t): 
    return hashlib.sha256(t.encode("utf-8")).hexdigest()

# ----------------------------
# âœ¨ ìœ í‹¸
# ----------------------------
def sanitize_folder_name(name: str) -> str:
    name = (name or "").strip()
    name = re.sub(r"[^\wê°€-í£\s]", "", name)
    name = re.sub(r"\s+", "_", name)
    return name.strip("_") or "ê¸°íƒ€_ë¬¸ì„œ"

# ----------------------------
# âœ¨ OpenAI í•¨ìˆ˜
# ----------------------------
def embed_titles(titles):
    vectors = []
    missing = []

    for t in titles:
        k = h(t)
        if k in embedding_cache:
            vectors.append(embedding_cache[k])
        else:
            missing.append(t)

    if missing:
        r = openai.Embedding.create(
            model="text-embedding-3-large",
            input=missing,
        )
        for t, d in zip(missing, r["data"]):
            embedding_cache[h(t)] = d["embedding"]
        save_cache(EMBED_CACHE, embedding_cache)

        vectors = [embedding_cache[h(t)] for t in titles]

    return vectors

def generate_group_name(names):
    k = h("||".join(sorted(names)))
    if k in group_cache:
        return group_cache[k]

    prompt = """
ë‹¤ìŒ ë¬¸ì„œ ì œëª©ë“¤ì˜ ê³µí†µ ì£¼ì œë¥¼ ëŒ€í‘œí•˜ëŠ”
ì§§ê³  ëª…í™•í•œ í•œê¸€ í´ë”ëª… í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ê·œì¹™:
- 2~4 ë‹¨ì–´
- ì¡°ì‚¬ ì‚¬ìš© ê¸ˆì§€
- ìˆ«ì/ë²ˆí˜¸ ê¸ˆì§€
- ì„¤ëª… ê¸ˆì§€
"""

    r = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” í•œê¸€ í´ë”ëª…ë§Œ ìƒì„±í•œë‹¤."},
            {"role": "user", "content": prompt + "\n" + "\n".join(names)},
        ],
        temperature=0.3,
    )

    name = sanitize_folder_name(r["choices"][0]["message"]["content"])
    group_cache[k] = name
    save_cache(GROUP_CACHE, group_cache)
    return name

def generate_readme(topic, files):
    k = h("ko||" + topic + "||" + "||".join(sorted(files)))
    if k in readme_cache:
        return readme_cache[k]

    prompt = f"""
ë‹¤ìŒ ë¬¸ì„œë“¤ì€ '{topic}' ì£¼ì œë¡œ ë¶„ë¥˜ëœ ìë£Œì…ë‹ˆë‹¤.
ê° ë¬¸ì„œì˜ ê´€ê³„ì™€ í™œìš© ëª©ì ì„ ì„¤ëª…í•˜ëŠ” README.mdë¥¼ ì‘ì„±í•˜ì„¸ìš”.
ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ë¬¸ì„œ ëª©ë¡:
{chr(10).join(files)}
"""

    r = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ì–´ë¡œë§Œ READMEë¥¼ ì‘ì„±í•œë‹¤."},
            {"role": "user", "content": prompt},
        ],
    )

    content = r["choices"][0]["message"]["content"].strip()
    readme_cache[k] = content
    save_cache(README_CACHE, readme_cache)
    return content

def cluster_documents(files):
    titles = [f"title: {f.name.split('.')[0]}" for f in files]
    return HDBSCAN(min_cluster_size=2).fit_predict(embed_titles(titles))

# ----------------------------
# ğŸš€ ë©”ì¸ ë¡œì§ (ì¤‘ë³µ ì œê±° ì™„ë£Œ)
# ----------------------------
if uploaded_files:
    progress = progress_placeholder.progress(0)
    progress_text.markdown("<div class='status-bar'>[0%]</div>", unsafe_allow_html=True)
    log("íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")

    output_dir = Path("output_docs")
    output_dir.mkdir(exist_ok=True)

    labels = cluster_documents(uploaded_files)
    groups = {}
    for f, l in zip(uploaded_files, labels):
        groups.setdefault(l, []).append(f)

    total = len(groups)
    done = 0

    for label, files in groups.items():
        main_group = (
            "ë¯¸ë¶„ë¥˜_ë¬¸ì„œ"
            if label == -1
            else generate_group_name([f.name.split(".")[0] for f in files])
        )

        main_folder = output_dir / main_group
        main_folder.mkdir(parents=True, exist_ok=True)

        # ğŸ“„ ëŒ€ë¶„ë¥˜ READMEë§Œ ìƒì„± (âŒ íŒŒì¼ ì €ì¥ ì•ˆ í•¨)
        main_readme = generate_readme(main_group, [f.name for f in files])
        (main_folder / "README.md").write_text(main_readme, encoding="utf-8")

        # ğŸ”¹ ì¤‘ë¶„ë¥˜
        sub_labels = cluster_documents(files)
        sub_groups = {}
        for f, sl in zip(files, sub_labels):
            sub_groups.setdefault(sl, []).append(f)

        for sl, sub_files in sub_groups.items():
            sub_group = (
                "ê¸°íƒ€"
                if sl == -1
                else generate_group_name([f.name.split(".")[0] for f in sub_files])
            )

            sub_folder = main_folder / sub_group
            sub_folder.mkdir(parents=True, exist_ok=True)

            # âœ… íŒŒì¼ ì €ì¥ì€ ì—¬ê¸°ì„œë§Œ!
            for f in sub_files:
                (sub_folder / f.name).write_bytes(f.getvalue())

            # ğŸ“„ ì¤‘ë¶„ë¥˜ README
            sub_readme = generate_readme(
                f"{main_group} - {sub_group}",
                [f.name for f in sub_files],
            )
            (sub_folder / "README.md").write_text(sub_readme, encoding="utf-8")

        done += 1
        pct = int(done / total * 100)
        progress.progress(pct)
        progress_text.markdown(
            f"<div class='status-bar'>[{pct}% ({done}/{total})]</div>",
            unsafe_allow_html=True,
        )
        log(f"{main_group} ì²˜ë¦¬ ì™„ë£Œ")

    with zipfile.ZipFile("result_documents.zip", "w") as z:
        for root, _, files in os.walk(output_dir):
            for f in files:
                p = os.path.join(root, f)
                z.write(p, arcname=os.path.relpath(p, output_dir))

    zip_placeholder.download_button(
        "ğŸ“¥ ì •ë¦¬ëœ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
        open("result_documents.zip", "rb"),
        file_name="result_documents.zip",
        mime="application/zip",
    )

    progress.progress(100)
    progress_text.markdown(
        "<div class='status-bar'>[100% complete]</div>",
        unsafe_allow_html=True,
    )
    log("ëª¨ë“  ë¬¸ì„œ ì •ë¦¬ ì™„ë£Œ")

else:
    progress_placeholder.progress(0)
    progress_text.markdown(
        "<div class='status-bar'>[ëŒ€ê¸° ì¤‘]</div>",
        unsafe_allow_html=True,
    )
    log_box.markdown("<div class='log-box'>ëŒ€ê¸° ì¤‘...</div>", unsafe_allow_html=True)
