# AI DAZY v2512190245_1.1

import streamlit as st
import zipfile
import os
import openai
import json
import hashlib
import re
import shutil
import secrets
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from pathlib import Path

# ============================
# ğŸ” Token Store (Server Memory)
# ============================
TOKEN_STORE = {}
TOKEN_EXPIRE_HOURS = 3

# ----------------------------
# ğŸŒˆ ê¸°ë³¸ í˜ì´ì§€ ì„¤ì •
# ----------------------------
st.set_page_config(
    page_title="AI dazy document sorter",
    page_icon="ğŸ—‚ï¸",
    layout="wide",
)

# ============================
# ğŸ”’ Password + Token Gate
# ============================
APP_PASSWORD = st.secrets.get("APP_PASSWORD") or os.getenv("APP_PASSWORD")

params = st.experimental_get_query_params()
token = params.get("auth", [None])[0]

if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

# í† í° ìˆìœ¼ë©´ ì¸ì¦ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
if token:
    st.session_state.authenticated = True

# ë¹„ì¸ì¦ ìƒíƒœ â†’ ë¹„ë°€ë²ˆí˜¸ ì…ë ¥
if not st.session_state.authenticated:
    st.markdown("<br><br><br><br>", unsafe_allow_html=True)
    col = st.columns([1, 2, 1])[1]

    with col:
        st.markdown(
            """
            <div style="
                background:#444;
                padding:2rem;
                border-radius:16px;
                text-align:center;
                color:white;">
                <h2>ğŸ”’ Access Password</h2>
                <p>ì´ ì•±ì€ ì œí•œëœ ì‚¬ìš©ìë§Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
            </div>
            """,
            unsafe_allow_html=True,
        )

        pw = st.text_input("Password", type="password", label_visibility="collapsed")

        if pw:
            if pw == APP_PASSWORD:
                new_token = secrets.token_hex(16)
                st.experimental_set_query_params(auth=new_token)
                st.session_state.authenticated = True
                st.success("ì ‘ê·¼ í—ˆìš©")
                st.rerun()
            else:
                st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    st.stop()

# ============================
# ğŸ”„ Restore API Session from Token
# ============================
if token and token in TOKEN_STORE:
    record = TOKEN_STORE[token]
    if datetime.utcnow() < record["expires_at"]:
        openai.api_key = record["api_key"]
        st.session_state.api_key = record["api_key"]
    else:
        TOKEN_STORE.pop(token, None)
        st.experimental_set_query_params()
        st.warning("â° API ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë¡œê·¸ì¸í•˜ì„¸ìš”.")
        st.stop()

# ============================
# ğŸ”‘ API Key Input (First Time)
# ============================
if "api_key" not in st.session_state:
    st.markdown("### ğŸ”‘ OpenAI API Key")

    api_key_input = st.text_input(
        "OpenAI API Key",
        type="password",
        placeholder="sk-xxxxxxxxxxxxxxxxxxxxxxxx",
        label_visibility="collapsed",
    )

    if api_key_input:
        try:
            openai.api_key = api_key_input
            openai.Model.list()  # ìœ íš¨ì„± ê²€ì‚¬

            TOKEN_STORE[token] = {
                "api_key": api_key_input,
                "expires_at": datetime.utcnow() + timedelta(hours=TOKEN_EXPIRE_HOURS),
            }

            st.session_state.api_key = api_key_input
            st.success("API Key ì¸ì¦ ì™„ë£Œ")
            st.rerun()
        except Exception:
            st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ API Keyì…ë‹ˆë‹¤.")

    st.stop()

# ============================
# âœ… API Session Active
# ============================
openai.api_key = st.session_state.api_key

st.success("âœ… API ì¸ì¦ì„±ê³µ ")

# ----------------------------
# ğŸ¨ ìŠ¤íƒ€ì¼
# ----------------------------
st.markdown(
    """
    
    <style>
    body { background-color: #f8f9fc; font-family: 'Pretendard', sans-serif; }
    .stButton>button {
        border-radius: 10px; background-color: #4a6cf7; color: white;
        border: none; padding: 0.6em 1.2em; font-weight: 600;
    }
    .stButton>button:hover { background-color: #3451c1; }
    .status-bar {
        background-color: #0e1117; border-radius: 6px;
        padding: 0.5em; margin-top: 10px; font-size: 0.9em;
    }
    .log-box {
        background-color: #262A32; border-radius: 6px;
        padding: 0.8em; margin-top: 10px;
        height: 120px; overflow-y: auto; font-size: 0.85em;
        border: none;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ----------------------------
# ğŸ§­ ì‚¬ì´ë“œë°”
# ----------------------------

# ============================
# ğŸ”’ Logout Button
# ============================
st.sidebar.title("âš™ï¸ Setting")
col1, col2 = st.sidebar.columns([1, 1], gap="small")

with col1:
    if st.button("ğŸ”‘ API Key ë³€ê²½", use_container_width=True):
        st.session_state.pop("api_key", None)
        st.rerun()

with col2:
    if st.button("ğŸ”’ ë¡œê·¸ì•„ì›ƒ", use_container_width=True):
    # ì¸ì¦ ìƒíƒœ ì œê±°
        st.session_state.pop("authenticated", None)
        st.session_state.pop("api_key", None)

    # URL í† í° ì œê±°
        st.experimental_set_query_params()

    # ì „ì²´ ë¦¬ì…‹
        st.rerun()


# ----------------------------
# ğŸ§  ìºì‹œ
# ----------------------------
CACHE_DIR = Path(".cache")
CACHE_DIR.mkdir(exist_ok=True)

def load_cache(p):
    try:
        return json.loads(p.read_text(encoding="utf-8")) if p.exists() else {}
    except Exception:
        return {}

def save_cache(p, d):
    p.write_text(json.dumps(d, ensure_ascii=False, indent=2), encoding="utf-8")

EMBED_CACHE = CACHE_DIR / "embeddings.json"
GROUP_CACHE = CACHE_DIR / "group_names.json"
README_CACHE = CACHE_DIR / "readmes.json"
EXPAND_CACHE = CACHE_DIR / "expands.json"

embedding_cache = load_cache(EMBED_CACHE)
group_cache = load_cache(GROUP_CACHE)
readme_cache = load_cache(README_CACHE)
expand_cache = load_cache(EXPAND_CACHE)

def reset_cache():
    if CACHE_DIR.exists():
        shutil.rmtree(CACHE_DIR)
    CACHE_DIR.mkdir(exist_ok=True)
    embedding_cache.clear()
    group_cache.clear()
    readme_cache.clear()
    expand_cache.clear()

def reset_output():
    output_dir = Path("output_docs")
    zip_path = Path("result_documents.zip")

    if output_dir.exists():
        shutil.rmtree(output_dir)
    if zip_path.exists():
        zip_path.unlink()

st.sidebar.markdown(
    """

- âš™ï¸ ë‹¤ì‹œ ì‹œì‘í•˜ì‹œë ¤ë©´ 
-     "Cache Reset > Download Reset > F5 ìˆœì„œëŒ€ë¡œ ëˆŒëŸ¬ì£¼ì„¸ìš”."
"""
)

# â–¶ ì‚¬ì´ë“œë°” ë²„íŠ¼ (ìºì‹œ, ë‹¤ìš´ë¡œë“œ ì´ˆê¸°í™”)

col1, col2 = st.sidebar.columns([1, 1], gap="small")

with col1:
    if st.button("ğŸ§¹ Cache Reset", use_container_width=True):
        reset_cache()
        st.toast("âœ… Cache Reset is complete.")
        st.rerun()

with col2:
    if st.button("ğŸ—‘ï¸ Download Reset", use_container_width=True):
        reset_output()
        st.toast("âœ… Download Reset is complete.")
        st.rerun()

def h(t: str):
    return hashlib.sha256(t.encode("utf-8")).hexdigest()


st.sidebar.markdown("### ğŸ’¡ ì‚¬ìš© íŒ")
st.sidebar.markdown(
    """
- ğŸ“ íŒŒì¼ì„ **ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì‹œì‘** ë©ë‹ˆë‹¤.
- ğŸ“‚ **ì—¬ëŸ¬ ë¬¸ì„œë¥¼ í•œ ë²ˆì— ì—…ë¡œë“œ**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ğŸ§  ë¬¸ì„œëŠ” **AIê°€ ìë™ìœ¼ë¡œ ì£¼ì œë³„ ë¶„ë¥˜**í•©ë‹ˆë‹¤.
- ğŸ“ í´ë” ìˆ˜ê°€ ë§ìœ¼ë©´ **ìë™ìœ¼ë¡œ í•˜ìœ„ í´ë”ë¡œ ë¶„í•´**ë©ë‹ˆë‹¤.
- â³ ë¬¸ì„œ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ì²˜ë¦¬ ì‹œê°„ì´ ëŠ˜ì–´ë‚©ë‹ˆë‹¤.
- ğŸ“¦ ì™„ë£Œ í›„ **ZIP íŒŒì¼ë¡œ í•œ ë²ˆì— ë‹¤ìš´ë¡œë“œ**í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
)

# ----------------------------
# ğŸ“ ë©”ì¸ UI
# ----------------------------
left_col, right_col = st.columns([1, 1])

st.subheader("AI auto file analyzer")
st.caption("ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìë™ìœ¼ë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤")

with left_col:
    st.subheader("File upload")
    uploaded_files = st.file_uploader(
        "ğŸ“ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.md, .pdf, .txt)",
        accept_multiple_files=True,
        type=["md", "pdf", "txt"],
    )

with right_col:
    st.subheader("ZIP Download")
    st.caption("ğŸ“ ë¬¸ì„œ ì •ë¦¬ í›„ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì´ í™œì„±í™” ë©ë‹ˆë‹¤.")

    st.markdown(
        '<div class="download-box">',
        unsafe_allow_html=True,
    )

    zip_placeholder = st.empty()

    st.markdown(
        '</div>',
        unsafe_allow_html=True,
    )

# ----------------------------
# âš™ï¸ ìƒíƒœ / ë¡œê·¸
# ----------------------------
progress_placeholder = st.empty()
progress_text = st.empty()
log_box = st.empty()
logs = []

def log(msg):
    logs.append(msg)
    log_box.markdown(
        "<div class='log-box'>" + "<br>".join(logs[-10:]) + "</div>",
        unsafe_allow_html=True,
    )

# ----------------------------
# âœ¨ ìœ í‹¸
# ----------------------------
def sanitize_folder_name(name: str) -> str:
    name = (name or "").strip()
    name = re.sub(r"[^\wê°€-í£\s]", "", name)
    name = re.sub(r"\s+", "_", name)
    return name.strip("_") or "ê¸°íƒ€_ë¬¸ì„œ"

def unique_folder_name(base: str, existing: set) -> str:
    if base not in existing:
        return base
    i = 1
    while f"{base}_{i}" in existing:
        i += 1
    return f"{base}_{i}"

def title_from_filename(file_name: str) -> str:
    base = file_name.rsplit(".", 1)[0]
    base = re.sub(r"[_\-]+", " ", base)
    base = re.sub(r"\s+", " ", base).strip()
    return base

# ----------------------------
# ğŸ§  0ì°¨ GPT EXPAND
# ----------------------------
def expand_document_with_gpt(file):
    key = h(file.name)
    if key in expand_cache:
        return expand_cache[key]

    fallback_title = title_from_filename(file.name)

    prompt = f"""
ë‹¤ìŒ ë¬¸ì„œë¥¼ ë¶„ë¥˜í•˜ê¸° ì‰½ê²Œ ì˜ë¯¸ì ìœ¼ë¡œ ì •ê·œí™”í•˜ë¼.
ë¶„ë¥˜ë‚˜ ê·¸ë£¹í•‘ì€ í•˜ì§€ ë§ê³ , ì˜ë¯¸ë§Œ ì¶”ì¶œí•˜ë¼.

ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í•˜ë‚˜ë§Œ ì¶œë ¥í•œë‹¤.

í˜•ì‹:
{{
  "canonical_title": "...",
  "keywords": ["...", "..."],
  "domain": "...",
  "embedding_text": "..."
}}

ë¬¸ì„œ íŒŒì¼ëª…:
{file.name}
"""

    try:
        r = openai.ChatCompletion.create(
            model="gpt-5-nano",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ë¬¸ì„œë¥¼ ë¶„ë¥˜í•˜ê¸° ì‰½ê²Œ ì •ê·œí™”í•˜ëŠ” ì—­í• ì´ë‹¤."},
                {"role": "user", "content": prompt},
            ],
            temperature=0.2,
        )
        data = json.loads(r["choices"][0]["message"]["content"])
        if "embedding_text" not in data:
            raise ValueError

    except Exception:
        data = {
            "canonical_title": fallback_title,
            "keywords": fallback_title.split(),
            "domain": "ê¸°íƒ€",
            "embedding_text": f"ì œëª©: {fallback_title}",
        }

    expand_cache[key] = data
    save_cache(EXPAND_CACHE, expand_cache)
    return data

# ----------------------------
# â­ ì¶”ê°€: 0ì°¨ EXPAND ë³‘ë ¬ ì²˜ë¦¬
# ----------------------------
def expand_documents_parallel(files, max_workers=5):
    results = {}
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(expand_document_with_gpt, f): f for f in files}
        for future in as_completed(futures):
            f = futures[future]
            try:
                results[f] = future.result()
            except Exception:
                fallback_title = title_from_filename(f.name)
                results[f] = {
                    "canonical_title": fallback_title,
                    "keywords": fallback_title.split(),
                    "domain": "ê¸°íƒ€",
                    "embedding_text": f"ì œëª©: {fallback_title}",
                }
    return [results[f] for f in files]

# ----------------------------
# âœ¨ ì„ë² ë”©
# ----------------------------
def embed_texts(texts):
    missing = [t for t in texts if h(t) not in embedding_cache]

    if missing:
        r = openai.Embedding.create(
            model="text-embedding-3-large",
            input=missing,
        )
        for t, d in zip(missing, r["data"]):
            embedding_cache[h(t)] = d["embedding"]
        save_cache(EMBED_CACHE, embedding_cache)

    return [embedding_cache[h(t)] for t in texts]

# ----------------------------
# ğŸ“¦ í´ëŸ¬ìŠ¤í„°ë§
# ----------------------------
def cluster_documents(files):
    # â­ ë³€ê²½: 0ì°¨ EXPAND ë³‘ë ¬ ì ìš©
    expanded = expand_documents_parallel(files, max_workers=5)
    vectors = embed_texts([e["embedding_text"] for e in expanded])
    return HDBSCAN(min_cluster_size=3, min_samples=1).fit_predict(vectors)

# ----------------------------
# ğŸ” ìë™ ì¬ë¶„í•´
# ----------------------------
def recursive_cluster(files, depth=0):
    if len(files) <= MAX_FILES_PER_CLUSTER or depth >= MAX_RECURSION_DEPTH:
        return [files]

    labels = cluster_documents(files)
    groups = {}
    for f, l in zip(files, labels):
        groups.setdefault(l, []).append(f)

    result = []
    for g in groups.values():
        if len(g) > MAX_FILES_PER_CLUSTER:
            result.extend(recursive_cluster(g, depth + 1))
        else:
            result.append(g)

    return result

# ----------------------------
# âœ¨ GPT í´ë”ëª… / README
# ----------------------------
def generate_group_name(names):
    k = h("||".join(sorted(names)))
    if k in group_cache:
        return group_cache[k]

    prompt = """
ë‹¤ìŒ ë¬¸ì„œ ì œëª©ë“¤ì˜ ê³µí†µ ì£¼ì œë¥¼ ëŒ€í‘œí•˜ëŠ”
ì§§ê³  ëª…í™•í•œ í•œê¸€ í´ë”ëª… í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ê·œì¹™:
- 2~4 ë‹¨ì–´
- ì¡°ì‚¬ ì‚¬ìš© ê¸ˆì§€
- ìˆ«ì/ë²ˆí˜¸ ê¸ˆì§€
- ì„¤ëª… ê¸ˆì§€
"""

    r = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” í•œê¸€ í´ë”ëª…ë§Œ ìƒì„±í•œë‹¤."},
            {"role": "user", "content": prompt + "\n" + "\n".join(names)},
        ],
        temperature=0.3,
    )

    name = sanitize_folder_name(r["choices"][0]["message"]["content"])
    group_cache[k] = name
    save_cache(GROUP_CACHE, group_cache)
    return name

def generate_readme(topic, files, auto_split=False):
    k = h(("split" if auto_split else "nosplit") + topic + "||" + "||".join(sorted(files)))
    if k in readme_cache:
        return readme_cache[k]

    notice = AUTO_SPLIT_NOTICE if auto_split else ""

    prompt = f"""
{notice}ë‹¤ìŒ ë¬¸ì„œë“¤ì€ '{topic}' ì£¼ì œë¡œ ë¶„ë¥˜ëœ ìë£Œì…ë‹ˆë‹¤.
ê° ë¬¸ì„œì˜ ê´€ê³„ì™€ í™œìš© ëª©ì ì„ ì„¤ëª…í•˜ëŠ” README.mdë¥¼ ì‘ì„±í•˜ì„¸ìš”.
ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.

ë¬¸ì„œ ëª©ë¡:
{chr(10).join(files)}
"""

    r = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” í•œêµ­ì–´ë¡œë§Œ READMEë¥¼ ì‘ì„±í•œë‹¤."},
            {"role": "user", "content": prompt},
        ],
    )

    content = notice + r["choices"][0]["message"]["content"].strip()
    readme_cache[k] = content
    save_cache(README_CACHE, readme_cache)
    return content

# ----------------------------
# ğŸš€ ë©”ì¸ ì²˜ë¦¬
# ----------------------------
if uploaded_files:
    uploaded_files = [f for f in uploaded_files if f and f.name.strip()]
    if not uploaded_files:
        st.stop()

    # â–¶ ì‹¤í–‰ ì‹œ ê²°ê³¼ í´ë” ìë™ ì´ˆê¸°í™”
    reset_output()

    output_dir = Path("output_docs")
    output_dir.mkdir(exist_ok=True)

    progress = progress_placeholder.progress(0)
    progress_text.markdown("<div class='status-bar'>[0%]</div>", unsafe_allow_html=True)
    log("íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")

    top_clusters = recursive_cluster(uploaded_files)
    total = len(top_clusters)
    done = 0

    for cluster_files in top_clusters:
        main_group = generate_group_name([f.name.rsplit(".", 1)[0] for f in cluster_files])
        main_folder = output_dir / main_group
        main_folder.mkdir(parents=True, exist_ok=True)

        (main_folder / "â˜…README.md").write_text(
            generate_readme(main_group, [f.name for f in cluster_files]),
            encoding="utf-8",
        )

        used_names = set()
        for sub_files in recursive_cluster(cluster_files):
            base = generate_group_name([f.name.rsplit(".", 1)[0] for f in sub_files])
            sub_group = unique_folder_name(base, used_names)
            used_names.add(sub_group)

            sub_folder = main_folder / sub_group
            sub_folder.mkdir(parents=True, exist_ok=True)

            for f in sub_files:
                (sub_folder / f.name).write_bytes(f.getvalue())

            (sub_folder / "â˜…README.md").write_text(
                generate_readme(f"{main_group} - {sub_group}", [f.name for f in sub_files]),
                encoding="utf-8",
            )

        done += 1
        pct = int(done / total * 100)
        progress.progress(pct)
        progress_text.markdown(
            f"<div class='status-bar'>ì •ë¦¬ ì¤‘â€¦ [{pct}%] ({done} / {total} íŒŒì¼)</div>",
            unsafe_allow_html=True
        )
        log(f"{main_group} ì²˜ë¦¬ ì™„ë£Œ")

    zip_path = Path("result_documents.zip")
    with zipfile.ZipFile(zip_path, "w") as z:
        for root, _, files in os.walk(output_dir):
            for f in files:
                p = os.path.join(root, f)
                z.write(p, arcname=os.path.relpath(p, output_dir))
 
    zip_placeholder.download_button(
        "[ Download ]",
        open("result_documents.zip", "rb"),
        file_name="result_documents.zip",
        mime="application/zip",
        use_container_width=True,
        key="zip_download",
    )

    progress.progress(100)
    progress_text.markdown("<div class='status-bar'>[100% complete]</div>", unsafe_allow_html=True)
    log("ëª¨ë“  ë¬¸ì„œ ì •ë¦¬ ì™„ë£Œ")

else:
    progress_placeholder.progress(0)
    progress_text.markdown("<div class='status-bar'>[ëŒ€ê¸° ì¤‘]</div>", unsafe_allow_html=True)
    log_box.markdown("<div class='log-box'>ëŒ€ê¸° ì¤‘...</div>", unsafe_allow_html=True)
