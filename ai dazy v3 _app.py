import streamlit as st
import zipfile
import os
from pathlib import Path
from openai import OpenAI
from hdbscan import HDBSCAN
import re
import json
import hashlib

# ----------------------------
# ğŸŒˆ ê¸°ë³¸ í˜ì´ì§€ ì„¤ì •
# ----------------------------
st.set_page_config(page_title="AI dazy document sorter", page_icon="ğŸ—‚ï¸", layout="wide")

# ----------------------------
# ğŸ” OpenAI API í‚¤ ì„¤ì •
# ----------------------------
api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

if not api_key:
    st.sidebar.error("ğŸš¨ OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤. secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()
else:
    st.sidebar.success("âœ… OpenAI Key ë¡œë“œ ì™„ë£Œ")

client = OpenAI(api_key=api_key)

# ----------------------------
# ğŸ¨ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•
# ----------------------------
st.markdown(
    """
    <style>
    body {
        background-color: #f8f9fc;
        font-family: 'Pretendard', sans-serif;
    }
    .stButton>button {
        border-radius: 10px;
        background-color: #4a6cf7;
        color: white;
        border: none;
        padding: 0.6em 1.2em;
        font-weight: 600;
        transition: 0.2s;
    }
    .stButton>button:hover {
        background-color: #3451c1;
    }
    .status-bar {
        background-color: #595656;
        border-radius: 6px;
        padding: 0.5em;
        margin-top: 20px;
        font-size: 0.9em;
    }
    .log-box {
        background-color: #595656;
        border-radius: 6px;
        padding: 0.8em;
        margin-top: 10px;
        height: 120px;
        overflow-y: auto;
        font-size: 0.85em;
        border: 1px solid #dee2e6;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ----------------------------
# ğŸ§­ ì‚¬ì´ë“œë°” ì„¤ì •
# ----------------------------
st.sidebar.title("âš™ï¸ ì„¤ì •")
if st.sidebar.button("ğŸ” ë‹¤ì‹œ ì‹œì‘"):
    st.session_state.clear()
    st.rerun()

lang = st.sidebar.selectbox("ğŸŒ ì–¸ì–´ ì„ íƒ", ["í•œêµ­ì–´", "English"])

# ----------------------------
# ğŸ“ ë©”ì¸ UI êµ¬ì„±
# ----------------------------
left_col, right_col = st.columns([1, 1])

with left_col:
    st.subheader("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader(
        "ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.md, .pdf, .txt)",
        accept_multiple_files=True,
        type=["md", "pdf", "txt"],
    )

if uploaded_files:
    uploaded_files = [f for f in uploaded_files if f and hasattr(f, "name") and f.name.strip()]
    if not uploaded_files:
        st.error("â— ìœ íš¨í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

with right_col:
    st.subheader("ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ")
    zip_placeholder = st.empty()

# ----------------------------
# âš™ï¸ ìƒíƒœ í‘œì‹œ / ë¡œê·¸
# ----------------------------
status_placeholder = st.empty()
log_box = st.empty()
log_messages = []

def log(msg):
    log_messages.append(msg)
    log_html = "<div class='log-box'>" + "<br>".join(log_messages[-10:]) + "</div>"
    log_box.markdown(log_html, unsafe_allow_html=True)

# ----------------------------
# ğŸ§  ìºì‹œ ì‹œìŠ¤í…œ
# ----------------------------
CACHE_DIR = Path(".cache")
CACHE_DIR.mkdir(exist_ok=True)

EMBED_CACHE = CACHE_DIR / "embeddings.json"
GROUP_CACHE = CACHE_DIR / "group_names.json"
README_CACHE = CACHE_DIR / "readmes.json"

def load_cache(path):
    return json.loads(path.read_text()) if path.exists() else {}

def save_cache(path, data):
    path.write_text(json.dumps(data, ensure_ascii=False, indent=2))

embedding_cache = load_cache(EMBED_CACHE)
group_cache = load_cache(GROUP_CACHE)
readme_cache = load_cache(README_CACHE)

def hash_key(text):
    return hashlib.sha256(text.encode()).hexdigest()

# ----------------------------
# âœ¨ OpenAI + ìºì‹œ ì ìš© í•¨ìˆ˜
# ----------------------------
def embed_titles(titles):
    vectors = []
    to_request = []

    for t in titles:
        key = hash_key(t)
        if key in embedding_cache:
            vectors.append(embedding_cache[key])
        else:
            to_request.append((t, key))

    if to_request:
        response = client.embeddings.create(
            model="text-embedding-3-large",
            input=[t for t, _ in to_request]
        )
        for emb, (_, key) in zip(response.data, to_request):
            embedding_cache[key] = emb.embedding
            vectors.append(emb.embedding)
        save_cache(EMBED_CACHE, embedding_cache)

    return vectors

def generate_group_name(file_names):
    key = hash_key("||".join(sorted(file_names)))
    if key in group_cache:
        return group_cache[key]

    prompt = f"""
    ë‹¤ìŒ ë¬¸ì„œ ì œëª©ë“¤ì„ ë³´ê³  ê³µí†µ ì£¼ì œë¥¼ ëŒ€í‘œí•˜ëŠ”
    ì§§ê³  ëª…í™•í•œ í•œê¸€ í´ë”ëª…ì„ í•˜ë‚˜ ìƒì„±í•˜ì„¸ìš”.

    ê·œì¹™:
    - ë±€_ìƒì
    - 2~4 ë‹¨ì–´
    - ì„¤ëª… ì—†ì´ ì´ë¦„ë§Œ ì¶œë ¥

    ë¬¸ì„œ ì œëª©:
    {chr(10).join(file_names)}
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You generate concise folder names."},
            {"role": "user", "content": prompt},
        ],
        max_tokens=20,
        temperature=0.2,
    )

    name = re.sub(r"[^a-z0-9_]", "", response.choices[0].message.content.strip())
    group_cache[key] = name or "misc_documents"
    save_cache(GROUP_CACHE, group_cache)
    return group_cache[key]

def generate_readme(topic, file_names):
    key = hash_key(topic + "||".join(sorted(file_names)))
    if key in readme_cache:
        return readme_cache[key]

    prompt = f"""
    ë‹¤ìŒ ë¬¸ì„œë“¤ì€ '{topic}' ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜ëœ ìë£Œì…ë‹ˆë‹¤.
    ê° ë¬¸ì„œì˜ ì‹œë„ˆì§€ íš¨ê³¼ë¥¼ ì„¤ëª…í•˜ëŠ” README.mdë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.

    ë¬¸ì„œ ëª©ë¡:
    {chr(10).join(file_names)}
    """

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
    )

    readme_cache[key] = response.choices[0].message.content.strip()
    save_cache(README_CACHE, readme_cache)
    return readme_cache[key]

def cluster_documents(files):
    titles = [f"title: {f.name.split('.')[0]}" for f in files]
    vectors = embed_titles(titles)
    clusterer = HDBSCAN(min_cluster_size=2, metric="euclidean")
    return clusterer.fit_predict(vectors)

# ----------------------------
# ğŸš€ ë©”ì¸ ì²˜ë¦¬ ë¡œì§
# ----------------------------
if uploaded_files:
    log("íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ âœ…")
    output_dir = Path("output_docs")
    output_dir.mkdir(exist_ok=True, parents=True)

    labels = cluster_documents(uploaded_files)

    raw_groups = {}
    for file, label in zip(uploaded_files, labels):
        raw_groups.setdefault(label, []).append(file)

    for i, (label, files) in enumerate(raw_groups.items(), start=1):
        names = [f.name.split(".")[0] for f in files]
        group = "unclassified_documents" if label == -1 else generate_group_name(names)

        folder = output_dir / group
        folder.mkdir(exist_ok=True, parents=True)

        for f in files:
            with open(folder / f.name, "wb") as out:
                out.write(f.read())

        readme = generate_readme(group, [f.name for f in files])
        (folder / "README.md").write_text(readme, encoding="utf-8")

        progress = int((i / len(raw_groups)) * 100)
        status_placeholder.markdown(
            f"<div class='status-bar'>[{progress}% processing]</div>",
            unsafe_allow_html=True,
        )
        log(f"ë¬¸ì„œ ê·¸ë£¹ '{group}' ì²˜ë¦¬ ì™„ë£Œ âœ…")

    with zipfile.ZipFile("result_documents.zip", "w") as zipf:
        for folder, _, files in os.walk(output_dir):
            for f in files:
                p = os.path.join(folder, f)
                zipf.write(p, arcname=os.path.relpath(p, output_dir))

    with open("result_documents.zip", "rb") as f:
        zip_placeholder.download_button(
            "ğŸ“¥ ì •ë¦¬ëœ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            f,
            file_name="result_documents.zip",
            mime="application/zip",
        )

    status_placeholder.markdown(
        "<div class='status-bar'>[100% complete â€“ ëª¨ë“  ë¬¸ì„œ ì •ë¦¬ ì™„ë£Œ]</div>",
        unsafe_allow_html=True,
    )

else:
    status_placeholder.markdown(
        "<div class='status-bar'>[0% processing (0/0 complete)]</div>",
        unsafe_allow_html=True,
    )
    log_box.markdown("<div class='log-box'>ëŒ€ê¸° ì¤‘...</div>", unsafe_allow_html=True)
