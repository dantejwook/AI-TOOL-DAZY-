import streamlit as st
import zipfile
import os
from pathlib import Path
import openai
from hdbscan import HDBSCAN
import json
import hashlib
import re

# ----------------------------
# ğŸŒˆ ê¸°ë³¸ í˜ì´ì§€ ì„¤ì •
# ----------------------------
st.set_page_config(page_title="AI dazy document sorter", page_icon="ğŸ—‚ï¸", layout="wide")

# ----------------------------
# ğŸ” OpenAI API í‚¤ ì„¤ì • (legacy ë°©ì‹)
# ----------------------------
openai.api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

if not openai.api_key:
    st.sidebar.error("ğŸš¨ OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤. secrets.toml ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()
else:
    st.sidebar.success("âœ… OpenAI Key ë¡œë“œ ì™„ë£Œ")

# ----------------------------
# ğŸ¨ ìŠ¤íƒ€ì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•
# ----------------------------
st.markdown(
    """
    <style>
    body {
        background-color: #f8f9fc;
        font-family: 'Pretendard', sans-serif;
    }
    .stButton>button {
        border-radius: 10px;
        background-color: #4a6cf7;
        color: white;
        border: none;
        padding: 0.6em 1.2em;
        font-weight: 600;
        transition: 0.2s;
    }
    .stButton>button:hover {
        background-color: #3451c1;
    }
    .status-bar {
        background-color: #595656;
        border-radius: 6px;
        padding: 0.5em;
        margin-top: 20px;
        font-size: 0.9em;
    }
    .log-box {
        background-color: #595656;
        border-radius: 6px;
        padding: 0.8em;
        margin-top: 10px;
        height: 120px;
        overflow-y: auto;
        font-size: 0.85em;
        border: 1px solid #dee2e6;
    }
    </style>
    """,
    unsafe_allow_html=True,
)

# ----------------------------
# ğŸ§­ ì‚¬ì´ë“œë°” ì„¤ì •
# ----------------------------
st.sidebar.title("âš™ï¸ ì„¤ì •")
if st.sidebar.button("ğŸ” ë‹¤ì‹œ ì‹œì‘"):
    st.session_state.clear()
    st.rerun()

lang = st.sidebar.selectbox("ğŸŒ ì–¸ì–´ ì„ íƒ", ["í•œêµ­ì–´", "English"])

# ----------------------------
# ğŸ“ ë©”ì¸ UI êµ¬ì„±
# ----------------------------
left_col, right_col = st.columns([1, 1])

with left_col:
    st.subheader("ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ")
    uploaded_files = st.file_uploader(
        "ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.md, .pdf, .txt)",
        accept_multiple_files=True,
        type=["md", "pdf", "txt"],
    )

if uploaded_files:
    uploaded_files = [f for f in uploaded_files if f and f.name.strip()]
    if not uploaded_files:
        st.error("â— ìœ íš¨í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

with right_col:
    st.subheader("ğŸ“¦ ZIP ë‹¤ìš´ë¡œë“œ")
    zip_placeholder = st.empty()

# ----------------------------
# âš™ï¸ ìƒíƒœ í‘œì‹œ / ë¡œê·¸
# ----------------------------
status_placeholder = st.empty()
log_box = st.empty()
log_messages = []

def log(msg):
    log_messages.append(msg)
    log_box.markdown(
        "<div class='log-box'>" + "<br>".join(log_messages[-10:]) + "</div>",
        unsafe_allow_html=True,
    )

# ----------------------------
# ğŸ§  ìºì‹œ
# ----------------------------
CACHE_DIR = Path(".cache")
CACHE_DIR.mkdir(exist_ok=True)

EMBED_CACHE = CACHE_DIR / "embeddings.json"
GROUP_CACHE = CACHE_DIR / "group_names.json"
README_CACHE = CACHE_DIR / "readmes.json"

def load_cache(p):
    return json.loads(p.read_text()) if p.exists() else {}

def save_cache(p, d):
    p.write_text(json.dumps(d, ensure_ascii=False, indent=2))

embedding_cache = load_cache(EMBED_CACHE)
group_cache = load_cache(GROUP_CACHE)
readme_cache = load_cache(README_CACHE)

def h(text):
    return hashlib.sha256(text.encode()).hexdigest()

# ----------------------------
# âœ¨ OpenAI í•¨ìˆ˜ (legacy + ìºì‹œ)
# ----------------------------
def embed_titles(titles):
    vectors = []
    to_call = []

    for t in titles:
        k = h(t)
        if k in embedding_cache:
            vectors.append(embedding_cache[k])
        else:
            to_call.append((t, k))

    if to_call:
        resp = openai.Embedding.create(
            model="text-embedding-3-large",
            input=[t for t, _ in to_call],
        )
        for d, (_, k) in zip(resp["data"], to_call):
            embedding_cache[k] = d["embedding"]
            vectors.append(d["embedding"])
        save_cache(EMBED_CACHE, embedding_cache)

    return vectors

def generate_group_name(names):
    k = h("||".join(sorted(names)))
    if k in group_cache:
        return group_cache[k]

    prompt = """
ë‹¤ìŒ ë¬¸ì„œ ì œëª©ë“¤ì˜ ê³µí†µ ì£¼ì œë¥¼ ëŒ€í‘œí•˜ëŠ”
ì§§ê³  ëª…í™•í•œ ì˜ë¬¸ í´ë”ëª… í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ê·œì¹™:
- ì†Œë¬¸ì
- snake_case
- 2~4 ë‹¨ì–´
- ì„¤ëª… ê¸ˆì§€
"""

    r = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "You generate folder names."},
            {"role": "user", "content": "\n".join(names)},
        ],
        temperature=0.2,
        max_tokens=20,
    )

    name = re.sub(r"[^a-z0-9_]", "", r["choices"][0]["message"]["content"])
    group_cache[k] = name or "misc_documents"
    save_cache(GROUP_CACHE, group_cache)
    return group_cache[k]

def generate_readme(topic, files):
    k = h(topic + "||".join(sorted(files)))
    if k in readme_cache:
        return readme_cache[k]

    prompt = f"""
ë‹¤ìŒ ë¬¸ì„œë“¤ì€ '{topic}' ê·¸ë£¹ìœ¼ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.
ê° ë¬¸ì„œ ê°„ì˜ ì‹œë„ˆì§€ì™€ í™œìš© ëª©ì ì„ ì„¤ëª…í•˜ëŠ” README.mdë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ë¬¸ì„œ ëª©ë¡:
{chr(10).join(files)}
"""

    r = openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
    )

    readme_cache[k] = r["choices"][0]["message"]["content"]
    save_cache(README_CACHE, readme_cache)
    return readme_cache[k]

def cluster_documents(files):
    titles = [f"title: {f.name.split('.')[0]}" for f in files]
    vectors = embed_titles(titles)
    return HDBSCAN(min_cluster_size=2).fit_predict(vectors)

# ----------------------------
# ğŸš€ ë©”ì¸ ì²˜ë¦¬
# ----------------------------
if uploaded_files:
    log("íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ âœ…")
    output_dir = Path("output_docs")
    output_dir.mkdir(exist_ok=True)

    labels = cluster_documents(uploaded_files)

    groups = {}
    for f, l in zip(uploaded_files, labels):
        groups.setdefault(l, []).append(f)

    for i, (label, files) in enumerate(groups.items(), 1):
        names = [f.name.split(".")[0] for f in files]
        group = "unclassified_documents" if label == -1 else generate_group_name(names)

        folder = output_dir / group
        folder.mkdir(exist_ok=True)

        for f in files:
            (folder / f.name).write_bytes(f.getvalue())

        readme = generate_readme(group, [f.name for f in files])
        (folder / "README.md").write_text(readme, encoding="utf-8")

        status_placeholder.markdown(
            f"<div class='status-bar'>[{int(i/len(groups)*100)}% processing]</div>",
            unsafe_allow_html=True,
        )
        log(f"ë¬¸ì„œ ê·¸ë£¹ '{group}' ì²˜ë¦¬ ì™„ë£Œ âœ…")

    with zipfile.ZipFile("result_documents.zip", "w") as z:
        for root, _, files in os.walk(output_dir):
            for f in files:
                p = os.path.join(root, f)
                z.write(p, arcname=os.path.relpath(p, output_dir))

    zip_placeholder.download_button(
        "ğŸ“¥ ì •ë¦¬ëœ ZIP íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
        open("result_documents.zip", "rb"),
        file_name="result_documents.zip",
        mime="application/zip",
    )

    status_placeholder.markdown(
        "<div class='status-bar'>[100% complete â€“ ëª¨ë“  ë¬¸ì„œ ì •ë¦¬ ì™„ë£Œ]</div>",
        unsafe_allow_html=True,
    )

else:
    status_placeholder.markdown(
        "<div class='status-bar'>[0% processing (0/0 complete)]</div>",
        unsafe_allow_html=True,
    )
    log_box.markdown("<div class='log-box'>ëŒ€ê¸° ì¤‘...</div>", unsafe_allow_html=True)
